# -*- coding: utf-8 -*-
"""Welcome To Colab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

# Install required libraries
!pip install openai-whisper pymupdf sentence-transformers gradio

import whisper
import fitz
from sentence_transformers import SentenceTransformer, util
import numpy as np
import gradio as gr

def extract_text_from_pdf(pdf_path):
    """Extracts text from a given PDF file."""
    try:
        doc = fitz.open(pdf_path)
        text = "\n".join(page.get_text("text").strip() for page in doc)
        return text
    except Exception as e:
        print(f"❌ Error reading PDF: {e}")
        return ""

def transcribe_audio_locally(audio_path):
    """Transcribes speech using OpenAI's Whisper local model."""
    try:
        model = whisper.load_model("base")
        result = model.transcribe(audio_path)
        return result["text"]
    except Exception as e:
        print(f"❌ Whisper Transcription Error: {e}")
        return ""

def search_pdf_text(query, pdf_text):
    """Finds the most relevant sentences in the PDF matching the query using semantic similarity."""
    sentences = [s.strip() for s in pdf_text.split(". ") if s.strip()]

    model = SentenceTransformer('all-MiniLM-L6-v2')

    query_embedding = model.encode(query, convert_to_tensor=True)
    sentence_embeddings = model.encode(sentences, convert_to_tensor=True)

    cos_scores = util.cos_sim(query_embedding, sentence_embeddings)[0]

    top_results = np.argsort(-cos_scores)[:3]

    if len(top_results) > 0:
        return "\n".join([sentences[i] for i in top_results])
    else:
        return "No relevant match found."

def process_files(audio_file, pdf_file):
    """Processes uploaded audio and PDF files."""
    transcribed_query = transcribe_audio_locally(audio_file)

    pdf_text = extract_text_from_pdf(pdf_file)

    search_results = search_pdf_text(transcribed_query, pdf_text)

    return transcribed_query, search_results

iface = gr.Interface(
    fn=process_files,
    inputs=[
        gr.Audio(type="filepath", label="Upload Audio File"),
        gr.File(label="Upload PDF File")
    ],
    outputs=[
        gr.Textbox(label="Transcribed Query"),
        gr.Textbox(label="Matching Text from PDF")
    ],
    title="Whisper AI + PDF Search App",
    description="Upload an audio file and a PDF file to transcribe the audio and find relevant content in the PDF."
)

iface.launch()